# 多云监控方案

## 背景

在单集群部署场景中，promtail采集每个节点的日志数据并上传到loki存储中，客户端通过resource-manager访问loki中的日志数据。

![log-2025-04-07](https://fourt-wyq.oss-cn-shanghai.aliyuncs.com/images/log-2025-04-07.png)


在多集群部署场景中，子集群中的promtail采集每个节点的日志数据并上传到子集群中的loki存储中，客户端通过karmada访问resource-manager来访问子集群中loki中的日志数据。

![log-1-2025-04-07](https://fourt-wyq.oss-cn-shanghai.aliyuncs.com/images/log-1-2025-04-07.png)

## 问题描述

在多云场景下，用户通过主控集群下发任务到子集群中，按照当前的日志方案，用户的数据是保存在子集群loki配置的存储中，如果用户需要查询历史数据，连接子集群loki进行查询。这种方案存在如下问题：
- 子集群与主控集群断联后，用户无法查询历史数据


## 实现思路

1. 在系统测完成：日志数据统一存储在主控集群，用户查询历史数据时，直接查询主控集群即可。
2. 在用户测完成：告诉用户日志数据存在有效期，提供重要日志持久化，在子集群断联的情况下，备份日志到主控集群。


## 技术选型

### promtail + loki + memchche


单集群服务架构如下所示：

![log-11-2025-04-07](https://fourt-wyq.oss-cn-shanghai.aliyuncs.com/images/log-11-2025-04-07.png)

多集群服务架构如下所示：
![log-14-2025-04-07](https://fourt-wyq.oss-cn-shanghai.aliyuncs.com/images/log-14-2025-04-07.png)

- `Promtail`: 每个节点部署副本，采集日志数据，并将数据发送到loki。
    promtail的数据采集来源如下：
   - `/var/log/pods/*/*.log`:  
    ```bash
    [root@local-94 charts]# ll /var/log/pods
    total 0
    drwxr-xr-x 3 root root 23 Mar  6 14:56 kube-system_calicoctl-xhs95_2094de66-6808-40fd-a99b-792658e16d71
    drwxr-xr-x 3 root root 37 Mar  6 14:56 kube-system_calico-kube-controllers-5955986f9c-m555d_6cacffa2-8cd3-4670-9a46-8544b381691a
    ...
    ```
  - `/var/log/journal`：需要配置journalctl日志持久化存储，不然重启之前的数据都是丢失的。

- `Loki`：存储数据，提供查询接口。
    - `Distributor`：日志写入入口，接收 Promtail/Agent 发送的日志；使用一致性哈希环分配日志到目标 Ingester；支持水平扩展，无状态设计。
    - `Ingester`：内存存储日志数据（按租户和标签索引）；定期将数据持久化到对象存储（S3/GCS 等）。
    - `Query Frontend`：查询入口，处理用户查询请求；支持缓存查询结果（本地 / Redis）；转发查询到 Query Scheduler。
    - `Querier`：优先查 Ingester 内存数据，然后在查询持久化数据。
- `Memchche`：提供缓存索引写入和查询，块缓存。

存在的问题：
1. 因promtail无法将数据发送到多个loki，所以当子集群和主控集群都提供查询服务的时候，子集群需要部署两套prometail，浪费资源；
2. 在多个子集群都发送数据到主控集群，对主控集群的网络造成很大压力。

#### 接口性能测试

对比在有无部署memcache的情况下，loki的查询接口性能差异。

| 接口 | 名称 | 总请求数 |	失败数	| 失败率 | 平均响应时间 | 	最小响应 (ms) | 最大响应 (ms)| 	90% (ms)	| 95% (ms)	| 99% (ms)	| TPS	| 平均接收流量	| 每秒请求数
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| GET http://10.0.102.94:31301/loki/api/v1/query_range?query={container="compactor"} =``&start=1743492573284383211&end=1743492673284383211&limit=1000 | loki 原生接口查询 | 415 | 0 | 0% | 91.47 | 0 | 320 | 110 | 197 | 274 | 7.4 | 1.37 | 6.86 | 
| GET http://10.0.102.94:32250/loki/api/v1/query_range?query={container="compactor"} =``&start=1743492573284383211&end=1743492673284383211&limit=1000 | loki 原生接口查询 | 413 | 0 | 0% | 87.47 | 53 | 370 | 97 | 180 | 281 | 7.27 | 1.34 | 6.74 | 

通过grafana 获取memcache相关指标如下图：

![log-3-2025-04-07](https://fourt-wyq.oss-cn-shanghai.aliyuncs.com/images/log-3-2025-04-07.png)

结论： 在有无部署memcache的情况下，带有缓存的接口响应更快一些。


### Elasticsearch + Filebeat + Kibana +  INFINI Console

[INFINI Console](https://github.com/infinilabs/console) 是一个轻量级的多集群、跨版本统一的Elasticsearch / Opensearch / Easysearch治理平台。

服务架构图如下：

![log-9-2025-04-07](https://fourt-wyq.oss-cn-shanghai.aliyuncs.com/images/log-9-2025-04-07.png)

EFK（Elasticsearch + Filebeat + Kibana）日志系统是一种常见的解决方案，根据抓取日志组件不同存在以下几种组合：
- ELK（Elasticsearch，Logstash，Kibana）
- EFK（Elasticsearch，Filebeat，Kibana）
- EFK（Elasticsearch，Fluentd，Kibana）

EFK部署安装流程如下：

```bash
helm repo add elastic https://helm.elastic.co

helm pull elastic/elasticsearch
helm install elasticsearch ./elasticsearch -n log

helm pull elastic/kibana
helm install kibana ./kibana -n log

helm pull elastic/filebeat
helm install filebeat ./filebeat -n log
```
EFK日志查询功能验证如下：

![log-4-2025-04-07](https://fourt-wyq.oss-cn-shanghai.aliyuncs.com/images/log-4-2025-04-07.png)

存在的问题：
1. 无法做到统一日志存储。


### Elasticsearch + Filebeat + Kibana + Cross-Cluster Search

`跨集群搜索（cross-cluster search）`使你可以针对一个或多个远程集群运行单个搜索请求。这是Elasticsearch本身特性。

![log-8-2025-04-07](https://fourt-wyq.oss-cn-shanghai.aliyuncs.com/images/log-8-2025-04-07.png)

当我们的client向集群cluster_1发送请求时，它可以搜索自己本身的集群，同时也可以向另外的两个集群cluster_2及cluster_3发送请求。最后的结果由cluster_1返回给客户端。

存在的问题：
1. 无法做到统一日志存储。

### Clickhouse

功能特性：

`大数据量`：CK 的分布式架构支持动态扩缩容，可支撑海量数据存储。
`写入性能`：CK 的 MergeTree 表的写入速度在200MB/s，具有很高吞吐，写入基本没有瓶颈。
`查询性能`：CK 支持分区索引和排序索引，具有很高的检索效率，单机每秒可扫描数百万行的数据。
`存储成本`：CK 基于列式存储，数据压缩比很高，同时基于HDFS做冷热分离，能够进一步地降低存储成本。

存在的问题：
1. 需要根据业务构建日志表。目前还没有开源处理基于k8s日志的方案。


## 方案设计

根据调研情况，思路一方案目前无法实现，原因如下：
1. ES并没有实现统一存储。
2. loki方案，对主控集群带宽有要求，接入的集群越多，网络压力越大。

采用思路2的情况下，实现方式如下：
（1）根据任务的来源（主控集群/子集群）将数据保存到不同集群的用户存储中。
（2）用户任务日志同步到子集群的日志存储中，定时同步数据到主控集群。

调整项：

产品：需要考虑如何向告知用户日志的保存周期，以及如何持久化日志数据。
系统测：
（1）需要调整日志全量保存接口，需要根据pod标签判断日志保存到哪里。

存在的问题：主控的存储信息如何同步到子集群？



## 版本升级/数据迁移

无升级方案

## 参考文档
[多集群的日志聚合](https://mp.weixin.qq.com/s/byB9F9T7lCAEe9sqKEp_8w)
https://mp.weixin.qq.com/s/J2jiuBm8nKTvF_hnDlkH3g

https://zhuanlan.zhihu.com/p/554103626
https://mp.weixin.qq.com/s/x2_T5zESi0nOW5k1ETZc7g
