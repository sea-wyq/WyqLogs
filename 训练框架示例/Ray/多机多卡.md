
[RayCluster Quickstart — Ray 2.9.0](https://docs.ray.io/en/latest/cluster/kubernetes/getting-started/raycluster-quick-start.html#kuberay-raycluster-quickstart)

[Train PyTorch ResNet model with GPUs on Kubernetes — Ray 2.9.0](https://docs.ray.io/en/latest/cluster/kubernetes/examples/gpu-training-example.html#kuberay-gpu-training-example)

(1)创建一个k8s集群。

(2)部署创建raycluster

```bash
helm repo add kuberay https://ray-project.github.io/kuberay-helm/
helm repo update


helm install kuberay-operator kuberay/kuberay-operator --version 1.0.0
helm install raycluster kuberay/ray-cluster --version 1.0.0
```

(3) 将svc/raycluster-kuberay-head-svc 的type改为NodePort

```bash
kuebctl get svc raycluster-kuberay-head-svc
kubectl edit svc raycluster-kuberay-head-svc
```

(4) 在集群环境中安装ray

```bash
pip install 'ray[default]'
```

(5)执行测试命令

```bash
ray job submit --address http://10.0.102.46:6667 -- python -c "import ray; ray.init(); print(ray.cluster_resources())"
```

测试结果（成功）：展示当前集群拥有的资源

（5）删除ray cluster

```bash
# [Step 5.1]: Delete the RayCluster CR
# Uninstall the RayCluster Helm chart
helm uninstall raycluster
# release "raycluster" uninstalled

# Note that it may take several seconds for the Ray pods to be fully terminated.
# Confirm that the RayCluster's pods are gone by running
kubectl get pods

# NAME                                READY   STATUS    RESTARTS   AGE
# kuberay-operator-7fbdbf8c89-pt8bk   1/1     Running   0          XXm

# [Step 5.2]: Delete the KubeRay operator
# Uninstall the KubeRay operator Helm chart
helm uninstall kuberay-operator
# release "kuberay-operator" uninstalled

# Confirm that the KubeRay operator pod is gone by running
kubectl get pods
# No resources found in default namespace.

# [Step 5.3]: Delete the Kubernetes cluster
kind delete cluster

```

(6) 模型训练demo

训练脚本：train.py

```bash
import os
from typing import Dict
import ray
import torch
from filelock import FileLock
from torch import nn
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
from torchvision.transforms import Normalize, ToTensor
from tqdm import tqdm

import ray.train
from ray.train import ScalingConfig
from ray.train.torch import TorchTrainer


def get_dataloaders(batch_size):

    transform = transforms.Compose([ToTensor(), Normalize((0.5,), (0.5,))])
    with FileLock(os.path.expanduser("~/data.lock")):
        training_data = datasets.FashionMNIST(root="~/data",train=True,download=True,transform=transform)
        test_data = datasets.FashionMNIST(root="~/data",train=False,download=True,transform=transform)
    train_dataloader = DataLoader(training_data, batch_size=batch_size)
    test_dataloader = DataLoader(test_data, batch_size=batch_size)

    return train_dataloader, test_dataloader


# Model Definition
class NeuralNetwork(nn.Module):
    def __init__(self):
        super(NeuralNetwork, self).__init__()
        self.flatten = nn.Flatten()
        self.linear_relu_stack = nn.Sequential(
            nn.Linear(28 * 28, 512),
            nn.ReLU(),
            nn.Dropout(0.25),
            nn.Linear(512, 512),
            nn.ReLU(),
            nn.Dropout(0.25),
            nn.Linear(512, 10),
            nn.ReLU(),
        )

    def forward(self, x):
        x = self.flatten(x)
        logits = self.linear_relu_stack(x)
        return logits


def train_func_per_worker(config: Dict):
    lr = config["lr"]
    epochs = config["epochs"]
    batch_size = config["batch_size_per_worker"]

    train_dataloader, test_dataloader = get_dataloaders(batch_size=batch_size)
    train_dataloader = ray.train.torch.prepare_data_loader(train_dataloader)
    test_dataloader = ray.train.torch.prepare_data_loader(test_dataloader)

    model = NeuralNetwork()
    model = ray.train.torch.prepare_model(model)

    loss_fn = nn.CrossEntropyLoss()
    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)

    for epoch in range(epochs):
        model.train()
        for X, y in tqdm(train_dataloader, desc=f"Train Epoch {epoch}"):
            pred = model(X)
            loss = loss_fn(pred, y)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

        model.eval()
        test_loss, num_correct, num_total = 0, 0, 0
        with torch.no_grad():
            for X, y in tqdm(test_dataloader, desc=f"Test Epoch {epoch}"):
                pred = model(X)
                loss = loss_fn(pred, y)

                test_loss += loss.item()
                num_total += y.shape[0]
                num_correct += (pred.argmax(1) == y).sum().item()

        test_loss /= len(test_dataloader)
        accuracy = num_correct / num_total

        ray.train.report(metrics={"loss": test_loss, "accuracy": accuracy})


def train_fashion_mnist(num_workers=2, use_gpu=False):
    global_batch_size = 32
    ray.init()
    train_config = {
        "lr": 1e-3,
        "epochs": 10,
        "batch_size_per_worker": global_batch_size // num_workers,
    }

    scaling_config = ScalingConfig(num_workers=num_workers, use_gpu=use_gpu)

    trainer = TorchTrainer(
        train_loop_per_worker=train_func_per_worker,
        train_loop_config=train_config,
        scaling_config=scaling_config,
    )

    result = trainer.fit()
    print(f"Training result: {result}")

if __name__ == "__main__":
    train_fashion_mnist(num_workers=2, use_gpu=True)

```

执行命令：该指令的train.py是ray cluster的head pod里面的train.py，不是在执行命令的宿主机上。

```bash
ray job submit --address http://10.0.102.46:6667 -- python train.py
```

ray与torch的版本存在兼容性问题

目前最新的ray 2.9.0与python3.9 、torch 1.10.0+cu111 、 torchvision 0.11.0+cu111   可以运行
      torch  2.1.2+cu118、   torchvision 0.16.2+cu118    无法运行
      torch  1.10.2+cu111、 torchvision  0.11.3+cu111 可以运行
      torch 1.12.1+cu113  、torchvision  0.13.1+cu113 可以运行
      torch 1.11.0+cu115、  torchvision  0.12.0+cu115 可以运行
      torch  1.13.1+cu116、 torchvision 0.14.1+cu116 可以运行

pip3 install torch torchvision torchaudio --index-url <https://download.pytorch.org/whl/cu118>
pip3 install torch torchvision torchaudio --index-url <https://download.pytorch.org/whl/cu111>

ray helm包安装（无法在线安装，直接通过代码部署）

helm 仓库地址： [ray-project/kuberay-helm: Helm charts for the KubeRay project](https://github.com/ray-project/kuberay-helm)
