# 秒级监控方案

## 问题背景

在网络监控中，当前Prometheus采集数据最小的时间周期是15s,如果两次采集点数据正常，用户就会认为网络性能是正常的，实际上15s之间如果突发大幅的网络波动是无法感知的。采集频率1s和15s的网络指标对比如下图所示：

![second-6-2025-04-16](https://fourt-wyq.oss-cn-shanghai.aliyuncs.com/images/second-6-2025-04-16.png)

方案目标如下：
1. 在完成网络秒级监控的情况下，保证Prometheus的存储性能和稳定性。
2. 在产品上如何展示秒级监控数据，让用户直观的感受到网络指标数据的变化。


## 方案验证

### 竞品分析

`去哪儿旅行`秒级监控预警方案结构图如下：
![second-5-2025-04-16](https://fourt-wyq.oss-cn-shanghai.aliyuncs.com/images/second-5-2025-04-16.png)


[阿里云秒级监控功能详述](https://help.aliyun.com/zh/slb/network-load-balancer/user-guide/nlb-access-high-precision-second-monitoring-to-be-modified)

[华为云秒级监控功能详述](https://support.huaweicloud.com/intl/zh-cn/usermanual-dds/dds_03_0090.html)

[火山云秒级监控功能详述](https://www.volcengine.com/docs/6419/1131755)


### 技术选型

#### pushgateway

**实现思路：** 使用自定义的exporter，将网络监控指标按照规定的采集频率推送到pushgateway，然后由Prometheus从pushgateway中定期拉取数据。

方案结构图如下：

![second-4-2025-04-16](https://fourt-wyq.oss-cn-shanghai.aliyuncs.com/images/second-4-2025-04-16.png)

**结论：在使用pushgateway的时候，自定义的exporter无法上传携带时间戳的数据。无法实现秒级监控的功能。**

![second-2025-04-16](https://fourt-wyq.oss-cn-shanghai.aliyuncs.com/images/second-2025-04-16.png)

#### 秒级监控Prometheus

**实现思路：** 通过新增一个Prometheus来保存秒级监控的监控指标，默认只收集hero-user命名空间的监控指标。并只保存较短的时间周期数据（例如一天）。

方案结构图如下：

![second-3-2025-04-16](https://fourt-wyq.oss-cn-shanghai.aliyuncs.com/images/second-3-2025-04-16.png)
**功能验证：** 调整kubelet(cadvisor)的配置，将默认的30s采集频率调整为1s。对应的servicemonitor配置修改如下：

```bash
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  labels:
    app.kubernetes.io/name: kubelet
    app.kubernetes.io/part-of: kube-prometheus
  name: kubelet
  namespace: monitoring
spec:
  endpoints:
  - bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
    honorLabels: true
    honorTimestamps: false
    interval: 1s
    metricRelabelings:
    - action: drop
      regex: container_(network_tcp_usage_total|network_udp_usage_total|tasks_state|cpu_load_average_10s)
      sourceLabels:
      - __name__
    - action: drop
      regex: (container_spec_.*|container_file_descriptors|container_sockets|container_threads_max|container_threads|container_start_time_seconds|container_last_seen);;
      sourceLabels:
      - __name__
      - pod
      - namespace
    - action: drop
      regex: (container_blkio_device_usage_total);.+
      sourceLabels:
      - __name__
      - container
    path: /metrics/cadvisor
    port: https-metrics
    relabelings:
    - action: replace
      sourceLabels:
      - __metrics_path__
      targetLabel: metrics_path
    scheme: https
    tlsConfig:
      insecureSkipVerify: true
  jobLabel: app.kubernetes.io/name
  namespaceSelector:
    matchNames:
    - kube-system
  selector:
    matchLabels:
      app.kubernetes.io/name: kubelet 
```
验证结果：
![second-1-2025-04-16](https://fourt-wyq.oss-cn-shanghai.aliyuncs.com/images/second-1-2025-04-16.png)

> Prometheus配置文件更新 
> `curl -X POST http://10.244.81.43:9090/-/reload`


**结论：实现简单，可以完成秒级监控的需求；在仅配置用户监控指标所需的指标后，Prometheus的存储压力和性能压力显著降低（0.7c/200M）；增加了exporter的负载。**


> 注： 单纯的提高网络监控的exporter的采集频率，对Prometheus本身增加了很大的存储压力和性能压力，并且存储传输item次数的限制。
> 当监控指标的发送速率超过10000 item/s，导致Prometheus接受数据失败。报错如下所示：
```bash
time=2025-03-21T09:10:26.836Z level=ERROR source=queue_manager.go:1670 msg="non-recoverable error" component=remote remote_name=d09508 url=http://mimir-nginx.mimir.svc:80/api/v1/push failedSampleCount=2000 failedHistogramCount=0 failedExemplarCount=0 err="server returned HTTP status 429 Too Many Requests: the request has been rejected because the tenant exceeded the ingestion rate limit, set to 10000 items/s with a maximum allowed burst of 200000. This limit is applied on the total number of samples, exemplars and metadata received across all distributors (err-mimir-tenant-max-ingestion-rate). To adjust the related per-tenant limits, configure -distributor.ingestion-rate-limit and -distributor.ingestion-burst-size, or contact your service administrator.\n
```


#### 自定义exporter + 秒级监控Prometheus
    
**实现思路：** 构建秒级监控exporter服务：通过将node-exporter中采集网络相关的监控指标的逻辑抽取出来，并通过秒级定时任务去采集数据和时间戳到缓存中，然后通过http接口暴露数据，供Prometheus采集定时采集。

整体结构图如下所示：

![second-8-2025-04-16](https://fourt-wyq.oss-cn-shanghai.aliyuncs.com/images/second-8-2025-04-16.png)

可以根据后期需求来动态调整不同类指标的采集间隔，比如网络指标可以调整为1s，cpu指标可以调整为10s，磁盘指标可以调整为10s等。

代码仓库：https://gitlab.bitahub.com/hero-os/hero-exporter/-/tree/dev?ref_type=heads


**结论： 可以实现秒级监控，并可实现后期业务需求的增加。但每次业务需求都需要定制开发**

## 解决方案

因Prometheus本身限制，每个exporter的采集频率是固定且唯一的，无法根据用户的意愿去调整对应用户监控指标的采集频率；针对多云主控集群，因存储IO过高和占用空间过大，子集群秒级监控的数据是不合适持久化到主控集群。

在实际应用场景中，秒级监控指标需要始终开启，在用户Prometheus的基础上，在部署一个prometheus 实例，专门用于秒级监控，用户可以自主选择是否开启秒级监控。新的Prometheus保存很短的时间数据，并不进行持久化。可以根据产品需求定制化秒级监控面板。

单集群结构图如下：

![second-3-2025-04-16](https://fourt-wyq.oss-cn-shanghai.aliyuncs.com/images/second-3-2025-04-16.png)


多集群结构如下：

![second-7-2025-04-16](https://fourt-wyq.oss-cn-shanghai.aliyuncs.com/images/second-7-2025-04-16.png)


实施流程：

1. 产品和前端需要构建一个秒级监控面板，考虑用户交互。
2. 系统测部署一个秒级Prometheus实例，采集秒级监控指标数据,并调整秒级监控面板指标。

## 结论

#TODO

## 参考文档

https://mp.weixin.qq.com/s/evc-50dYZfA0MvZs_GTX6Q
https://mp.weixin.qq.com/s/dF5YS7EPp6U_L0pCyx9_gg
https://zhuanlan.zhihu.com/p/31777906